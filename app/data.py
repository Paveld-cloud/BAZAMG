# app/data.py
import os
import io
import re
import time
import json
import math
import logging
from typing import Dict, Set, Tuple, List, Iterable, Optional

import pandas as pd
import aiohttp
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
from zoneinfo import ZoneInfo

# -------------------- –õ–æ–≥–≥–µ—Ä --------------------
logger = logging.getLogger("bot.data")

# -------------------- –ö–æ–Ω—Ñ–∏–≥ --------------------
# –ß–∏—Ç–∞–µ–º –∏–∑ app.config —Ç–æ, —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ —Ç–∞–º.
try:
    from app.config import (
        SPREADSHEET_URL,
        SAP_SHEET_NAME,          # –∏–º—è –ª–∏—Å—Ç–∞ —Å –¥–µ—Ç–∞–ª—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "SAP")
        IMAGES_SHEET_NAME,       # –∏–º—è –ª–∏—Å—Ç–∞ —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"), –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        USERS_SHEET_NAME,        # –∏–º—è –ª–∏—Å—Ç–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"), –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        DATA_TTL,                # —Å–µ–∫, —Å–∫–æ–ª—å–∫–æ –¥–µ—Ä–∂–∞—Ç—å df –≤ –ø–∞–º—è—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä 300..900)
        SEARCH_COLUMNS,          # —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ (—Ç–∏–ø, –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ, –∫–æ–¥, oem, –∏–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å)
    )
except Exception:
    # –ó–∞–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    SPREADSHEET_URL = os.getenv("SPREADSHEET_URL", "")
    SAP_SHEET_NAME = "SAP"
    IMAGES_SHEET_NAME = "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"   # –µ—Å–ª–∏ –ª–∏—Å—Ç–∞ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏–º
    USERS_SHEET_NAME = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"   # –µ—Å–ª–∏ –ª–∏—Å—Ç–∞ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏–º
    DATA_TTL = int(os.getenv("DATA_TTL", "600"))
    SEARCH_COLUMNS = ["—Ç–∏–ø", "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–∫–æ–¥", "oem", "–∏–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å"]

GOOGLE_APPLICATION_CREDENTIALS_JSON = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON", "")
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

# -------------------- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è --------------------
df: Optional[pd.DataFrame] = None
_last_load_ts: float = 0.0

# –ü–æ–∏—Å–∫ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
_search_index: Dict[str, Set[int]] = {}
_image_index: Dict[str, str] = {}

# –î–∏–∞–ª–æ–≥–∏ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ handlers.py)
user_state: Dict[int, dict] = {}
issue_state: Dict[int, dict] = {}

# –°–ø–∏—Å–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
SHEET_ALLOWED: Set[int] = set()
SHEET_ADMINS: Set[int] = set()
SHEET_BLOCKED: Set[int] = set()

# –®–∞–≥–∏ –¥–∏–∞–ª–æ–≥–∞ (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ handlers.py ‚Üí ConversationHandler)
ASK_QUANTITY, ASK_COMMENT, ASK_CONFIRM = range(3)

# -------------------- –£—Ç–∏–ª–∏—Ç—ã --------------------
def _norm_code(x: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–¥: lower + —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –¥–µ—Ñ–∏—Å—ã."""
    return re.sub(r"[\s\-]+", "", str(x or "").strip().lower())

def _norm_str(x: str) -> str:
    return str(x or "").strip().lower()

def now_local_str(tz_name: str = "Asia/Tashkent") -> str:
    tz = ZoneInfo(tz_name)
    return datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

def val(d: dict, key: str, default: str = "") -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –¥–æ—Å—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è row.to_dict()."""
    return str(d.get(key, default) or default)

def _extract_code_from_url(url: str) -> str:
    """
    –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç –ø—É—Ç–∏ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è:
    https://site.com/path/UZ005399.png -> uz005399
    """
    try:
        path = re.sub(r"[?#].*$", "", url)  # –æ–±—Ä–µ–∂–µ–º query/fragment
        tail = path.rsplit("/", 1)[-1]
        name = tail.rsplit(".", 1)[0]
        return _norm_code(name)
    except Exception:
        return ""

def _safe_col(df_: pd.DataFrame, col: str) -> Optional[pd.Series]:
    if col not in df_.columns:
        return None
    s = df_[col].astype(str).fillna("").str.strip().str.lower()
    return s

# -------------------- –§–æ—Ä–º–∞—Ç –∫–∞—Ä—Ç–æ—á–∫–∏ --------------------
def format_row(row: dict) -> str:
    return (
        f"üîπ –¢–∏–ø: {val(row, '—Ç–∏–ø')}\n"
        f"üì¶ –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: {val(row, '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ')}\n"
        f"üî¢ –ö–æ–¥: {val(row, '–∫–æ–¥')}\n"
        f"üì¶ –ö–æ–ª-–≤–æ: {val(row, '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ')}\n"
        f"üí∞ –¶–µ–Ω–∞: {val(row, '—Ü–µ–Ω–∞')} {val(row, '–≤–∞–ª—é—Ç–∞')}\n"
        f"üè≠ –ò–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å: {val(row, '–∏–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å')}\n"
        f"‚öôÔ∏è OEM: {val(row, 'oem')}"
    )

# -------------------- Google Sheets –∫–ª–∏–µ–Ω—Ç --------------------
def get_gs_client():
    if not GOOGLE_APPLICATION_CREDENTIALS_JSON:
        raise RuntimeError("GOOGLE_APPLICATION_CREDENTIALS_JSON –Ω–µ –∑–∞–¥–∞–Ω")
    try:
        info = json.loads(GOOGLE_APPLICATION_CREDENTIALS_JSON)
        creds = Credentials.from_service_account_info(info, scopes=SCOPES)
    except json.JSONDecodeError:
        # –Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª–æ–∂–∏–ª –ø—É—Ç—å –≤–º–µ—Å—Ç–æ JSON
        creds = Credentials.from_service_account_file(GOOGLE_APPLICATION_CREDENTIALS_JSON, scopes=SCOPES)
    client = gspread.authorize(creds)
    return client

# -------------------- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö --------------------
def _load_sap_dataframe() -> pd.DataFrame:
    client = get_gs_client()
    sh = client.open_by_url(SPREADSHEET_URL)
    ws = sh.worksheet(SAP_SHEET_NAME)
    records = ws.get_all_records()
    new_df = pd.DataFrame(records)

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    new_df.columns = [c.strip().lower() for c in new_df.columns]

    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö –ø–æ–ª–µ–π
    for col in ("–∫–æ–¥", "oem"):
        if col in new_df.columns:
            new_df[col] = new_df[col].astype(str).str.strip().str.lower()
    if "image" in new_df.columns:
        new_df["image"] = new_df["image"].astype(str).str.strip()

    return new_df

def _load_images_sheet() -> Dict[str, str]:
    """
    –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∑–∞–≥—Ä—É–∑–∏–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ª–∏—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å).
    –û–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: '–∫–æ–¥', 'image'. –í–æ–∑–≤—Ä–∞—â–∞–µ–º {norm_code: image_url}.
    """
    mapping: Dict[str, str] = {}
    try:
        client = get_gs_client()
        sh = client.open_by_url(SPREADSHEET_URL)
        ws = sh.worksheet(IMAGES_SHEET_NAME)
    except Exception:
        # –ª–∏—Å—Ç–∞ –Ω–µ—Ç ‚Äî –Ω–µ –æ—à–∏–±–∫–∞
        return mapping

    rows = ws.get_all_records()
    if not rows:
        return mapping

    df_img = pd.DataFrame(rows)
    df_img.columns = [c.strip().lower() for c in df_img.columns]
    if "–∫–æ–¥" not in df_img.columns or "image" not in df_img.columns:
        return mapping

    for _, r in df_img.iterrows():
        code = _norm_code(r.get("–∫–æ–¥", ""))
        url = str(r.get("image", "")).strip()
        if code and url:
            mapping[code] = url
    logger.info(f"image-index: –∏–∑ –ª–∏—Å—Ç–∞ '{IMAGES_SHEET_NAME}' –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {len(mapping)} —Å—Å—ã–ª–æ–∫")
    return mapping

def build_search_index(df_: pd.DataFrame) -> Dict[str, Set[int]]:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–µ–∫—Å: —Ç–æ–∫–µ–Ω -> –Ω–∞–±–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ —Å—Ç—Ä–æ–∫, –≥–¥–µ —Ç–æ–∫–µ–Ω –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –ª—é–±–æ–π –∏–∑ SEARCH_COLUMNS.
    """
    idx: Dict[str, Set[int]] = {}
    cols = [c for c in SEARCH_COLUMNS if c in df_.columns]
    for i, row in df_.iterrows():
        for c in cols:
            tokenized = re.findall(r"[a-zA-Z–∞-—è–ê-–Ø0-9]+", str(row.get(c, "")), flags=re.IGNORECASE)
            for t in tokenized:
                key = _norm_str(t)
                if not key:
                    continue
                idx.setdefault(key, set()).add(i)
    return idx

def build_image_index(df_: pd.DataFrame) -> Dict[str, str]:
    """
    –ò–Ω–¥–µ–∫—Å –∫–∞—Ä—Ç–∏–Ω–æ–∫ ‚Äî –¥–≤–∞ –ø—Ä–æ—Ö–æ–¥–∞ + —Å–ª–∏—è–Ω–∏–µ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º –ª–∏—Å—Ç–æ–º (–µ—Å–ª–∏ –µ—Å—Ç—å):
    A) –∫–ª—é—á = –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL (–ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
    B) —Ñ–æ–ª–±—ç–∫: –∫–ª—é—á = –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–æ–ª–æ–Ω–∫–µ '–∫–æ–¥', –µ—Å–ª–∏ –µ—Å—Ç—å image –∏ A –Ω–µ –ø–æ–∫—Ä—ã–ª.
    + –°–ª–∏–≤–∞–µ–º {–∫–æ–¥:image} –∏–∑ –ª–∏—Å—Ç–∞ IMAGES_SHEET_NAME.
    """
    index: Dict[str, str] = {}

    # A) –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∑ df.image
    if "image" in df_.columns:
        added_a = 0
        for _, row in df_.iterrows():
            raw_url = str(row.get("image", "")).strip()
            if not raw_url:
                continue
            key = _extract_code_from_url(raw_url)
            if not key:
                continue
            index[key] = raw_url
            added_a += 1
    else:
        added_a = 0

    # B) —Ñ–æ–ª–±—ç–∫ –ø–æ '–∫–æ–¥'
    added_b = 0
    if "image" in df_.columns and "–∫–æ–¥" in df_.columns:
        for _, row in df_.iterrows():
            raw_url = str(row.get("image", "")).strip()
            if not raw_url:
                continue
            code_val = _norm_code(row.get("–∫–æ–¥", ""))
            if not code_val or code_val in index:
                continue
            index[code_val] = raw_url
            added_b += 1

    # C) —Å–ª–∏—è–Ω–∏–µ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º –ª–∏—Å—Ç–æ–º
    ext = _load_images_sheet()
    before_merge = len(index)
    index.update(ext)
    merged_added = len(index) - before_merge

    logger.info(
        f"image-index: A(filename)={added_a}, B(code-col)={added_b}, "
        f"C(extra-sheet)={merged_added}, unique_keys={len(index)}"
    )
    return index

def ensure_fresh_data(force: bool = False):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–Ω–¥–µ–∫—Å–æ–≤ (–µ—Å–ª–∏ TTL –∏—Å—Ç—ë–∫ –∏–ª–∏ force=True).
    """
    global df, _search_index, _image_index, _last_load_ts

    need = (
        force
        or df is None
        or (time.time() - _last_load_ts > DATA_TTL)
    )
    if not need:
        return

    new_df = _load_sap_dataframe()
    df = new_df
    _search_index = build_search_index(df)
    _image_index = build_image_index(df)
    _last_load_ts = time.time()
    logger.info(f"‚úÖ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã –∏–Ω–¥–µ–∫—Å—ã")

async def ensure_fresh_data_async(force: bool = False):
    # –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π
    await asyncio_to_thread(ensure_fresh_data, force)

# -------------------- –ö–∞—Ä—Ç–∏–Ω–∫–∏ --------------------
async def find_image_by_code_async(code: str) -> str:
    """
    –í–µ—Ä–Ω—ë—Ç URL –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ø–æ –∫–æ–¥—É –¥–µ—Ç–∞–ª–∏.
    –ò—â–µ–º –ø–æ –∏–Ω–¥–µ–∫—Å—É, –∫–ª—é—á –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º (_norm_code).
    """
    ensure_fresh_data()
    if not code or _image_index is None:
        return ""
    key = _norm_code(code)
    return _image_index.get(key, "")

def normalize_drive_url(url: str) -> str:
    m = re.search(r"drive\.google\.com/(?:file/d/([-\w]{20,})|open\?id=([-\w]{20,}))", url)
    if m:
        file_id = m.group(1) or m.group(2)
        return f"https://drive.google.com/uc?export=download&id={file_id}"
    return url

async def resolve_ibb_direct_async(url: str) -> str:
    """
    –ï—Å–ª–∏ –ø—Ä–∏—à–ª—é—Ç ibb.co/<page>, –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –ø—Ä—è–º–æ–π og:image.
    –î–ª—è i.ibb.co/<hash>/file.png ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å.
    """
    try:
        if re.search(r"^https?://i\.ibb\.co/", url, re.I):
            return url
        if not re.search(r"^https?://ibb\.co/", url, re.I):
            return url
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status != 200:
                    return url
                html = await resp.text()
        m = re.search(r'<meta[^>]+property=["\']og:image["\'][^>]+content=["\']([^"\']+)["\']', html, re.I)
        return m.group(1) if m else url
    except Exception as e:
        logger.warning(f"resolve_ibb_direct_async error: {e}")
        return url

async def resolve_image_url_async(url_raw: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏–º —Å—Å—ã–ª–∫—É –∫ –≤–∏–¥—É, –∫–æ—Ç–æ—Ä—ã–π Telegram —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ç:
    - Google Drive -> –ø—Ä—è–º–æ–π uc?export=download
    - ibb.co page -> og:image
    - –ü—Ä–æ—á–µ–µ ‚Äî –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    """
    if not url_raw:
        return ""
    url = normalize_drive_url(url_raw)
    url = await resolve_ibb_direct_async(url)
    return url

# -------------------- –ü–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å --------------------
def match_row_by_index(tokens: List[str]) -> Set[int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã —Å—Ç—Ä–æ–∫, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –í–°–ï —Ç–æ–∫–µ–Ω—ã.
    """
    ensure_fresh_data()
    if not tokens:
        return set()
    tokens_norm = [_norm_str(t) for t in tokens if t]
    if not tokens_norm:
        return set()

    sets: List[Set[int]] = []
    for t in tokens_norm:
        s = _search_index.get(t, set())
        if not s:
            return set()  # –µ—Å–ª–∏ –∫–∞–∫–æ–≥–æ-—Ç–æ —Ç–æ–∫–µ–Ω–∞ –Ω–µ—Ç ‚Äî –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ
        sets.append(s)

    # –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–Ω–æ–∂–µ—Å—Ç–≤
    acc = sets[0].copy()
    for s in sets[1:]:
        acc &= s
        if not acc:
            break
    return acc

def squash(text: str) -> str:
    """–£–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–µ–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ lower (–¥–ª—è ¬´—Å–∫–ª–µ–µ–Ω–Ω–æ–≥–æ¬ª –ø–æ–∏—Å–∫–∞)."""
    return re.sub(r"[\W_]+", "", str(text or "").lower())

def normalize(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (–¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏)."""
    return re.sub(r"[^\w\s]", "", str(text or "").lower()).strip()

# -------------------- –≠–∫—Å–ø–æ—Ä—Ç --------------------
def _df_to_xlsx(df_: pd.DataFrame, filename: str = "export.xlsx") -> io.BytesIO:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
        df_.to_excel(writer, index=False)
    buf.seek(0)
    return buf

# -------------------- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ --------------------
def _parse_int(x) -> Optional[int]:
    try:
        v = int(str(x).strip())
        return v if v > 0 else None
    except Exception:
        return None

def load_users_from_sheet() -> Tuple[Set[int], Set[int], Set[int]]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–∏—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ö–µ–º—ã:
      - –∫–æ–ª–æ–Ω–∫–∏: user_id, role (admin|user|blocked)
      - –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –±—É–ª–µ–≤—ã: allowed, admin, blocked
      - –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ 'user_id' => allowed
    """
    allowed: Set[int] = set()
    admins: Set[int] = set()
    blocked: Set[int] = set()
    try:
        client = get_gs_client()
        sh = client.open_by_url(SPREADSHEET_URL)
        ws = sh.worksheet(USERS_SHEET_NAME)
    except Exception:
        logger.info("–õ–∏—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø—É—Å–∫–∞–µ–º –≤—Å–µ—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        return allowed, admins, blocked

    rows = ws.get_all_records()
    if not rows:
        logger.info("–õ–∏—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø—É—Å—Ç")
        return allowed, admins, blocked

    dfu = pd.DataFrame(rows)
    dfu.columns = [c.strip().lower() for c in dfu.columns]

    has_uid = "user_id" in dfu.columns
    has_role = "role" in dfu.columns
    has_allowed = "allowed" in dfu.columns
    has_admin = "admin" in dfu.columns
    has_blocked = "blocked" in dfu.columns

    for _, r in dfu.iterrows():
        uid = _parse_int(r.get("user_id") if has_uid else r.get("uid"))
        if not uid:
            continue

        if has_role:
            role = str(r.get("role", "")).strip().lower()
            if role in ("admin", "–∞–¥–º–∏–Ω"):
                admins.add(uid)
                allowed.add(uid)
            elif role in ("blocked", "ban", "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω"):
                blocked.add(uid)
            else:
                allowed.add(uid)
            continue

        # –±—É–ª–µ–≤—ã–µ —Ñ–ª–∞–≥–∏
        if has_blocked and str(r.get("blocked")).strip().lower() in ("1", "true", "–¥–∞", "y", "yes"):
            blocked.add(uid)
            continue
        if has_admin and str(r.get("admin")).strip().lower() in ("1", "true", "–¥–∞", "y", "yes"):
            admins.add(uid)
            allowed.add(uid)
            continue
        if has_allowed:
            if str(r.get("allowed")).strip().lower() in ("1", "true", "–¥–∞", "y", "yes"):
                allowed.add(uid)
            continue

        # –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫
        allowed.add(uid)

    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã: allowed={len(allowed)}, admins={len(admins)}, blocked={len(blocked)}")
    return allowed, admins, blocked

# -------------------- –•–µ–ª–ø–µ—Ä—ã –¥–ª—è async --------------------
import asyncio
async def asyncio_to_thread(func, *args, **kwargs):
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(None, lambda: func(*args, **kwargs))

