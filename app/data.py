import os
import re
import io
import json
import time
import math
import asyncio
from datetime import datetime
from typing import Optional, Dict, Any, Set, List, DefaultDict
from collections import defaultdict
from zoneinfo import ZoneInfo
from telegram.ext import ConversationHandler

ASK_QUANTITY, ASK_COMMENT, CONFIRM = range(3)

import aiohttp
import gspread
import pandas as pd
from pandas import DataFrame
from google.oauth2.service_account import Credentials

# ========================= –ù–ê–°–¢–†–û–ô–ö–ò / ENV =========================

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "")
SPREADSHEET_URL = os.getenv("SPREADSHEET_URL", "")
SHEET_NAME = (os.getenv("SHEET_NAME", "").strip() or "").strip()
CREDS_JSON = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON", "")

TZ_NAME = os.getenv("TIMEZONE", "Asia/Tashkent")
DATA_TTL = int(os.getenv("DATA_TTL", "300"))       # –∫–µ—à –¥–∞–Ω–Ω—ã—Ö (—Å–µ–∫)
USERS_TTL = int(os.getenv("USERS_TTL", "300"))     # –∫–µ—à –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (—Å–µ–∫)

SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

# ---- –ü–æ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞ (ENV + –¥–µ—Ñ–æ–ª—Ç) ----
DEFAULT_SEARCH_COLUMNS = [
    "—Ç–∏–ø", "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–∫–æ–¥", "oem", "–∏–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å",
    "–ø–∞—Ä—Ç –Ω–æ–º–µ—Ä", "oem –ø–∞—Ä—Ç –Ω–æ–º–µ—Ä",
]

_env = os.getenv("SEARCH_COLUMNS", "").strip()
try:
    from_env = json.loads(_env) if _env else []
    if not isinstance(from_env, list):
        from_env = []
except Exception:
    from_env = []

# –ò—Ç–æ–≥: –ø–æ—Ä—è–¥–æ–∫ –∏–∑ ENV —Å–æ—Ö—Ä–∞–Ω—è–µ–º, –Ω–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–æ–ª—è; –¥—É–±–ª–∏–∫–∞—Ç—ã —É–±–∏—Ä–∞–µ–º; –≤—Å—ë –≤ lower()
SEARCH_COLUMNS: List[str] = list(
    dict.fromkeys(
        [
            (c.strip().lower() if isinstance(c, str) else "")
            for c in (from_env + DEFAULT_SEARCH_COLUMNS)
            if c
        ]
    )
)

# ========================= –ì–õ–û–ë–ê–õ–¨–ù–´–ï –°–û–°–¢–û–Ø–ù–ò–Ø =========================

df: Optional[DataFrame] = None
_last_load_ts = 0.0
_search_index: Optional[Dict[str, Set[int]]] = None
_image_index: Optional[Dict[str, str]] = None

SHEET_ALLOWED: Set[int] = set()
SHEET_ADMINS: Set[int] = set()
SHEET_BLOCKED: Set[int] = set()
_last_users_ts = 0.0

# ========================= –£–¢–ò–õ–ò–¢–´ =========================

def now_local_str(fmt: str = "%Y-%m-%d %H:%M:%S") -> str:
    try:
        return datetime.now(ZoneInfo(TZ_NAME)).strftime(fmt)
    except Exception:
        return datetime.utcnow().strftime(fmt)

def val(row: dict, key: str, default: str = "‚Äî") -> str:
    v = row.get(key)
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return default
    s = str(v).strip()
    return s if s else default

def format_row(row: dict) -> str:
    return (
        f"üîπ –¢–∏–ø: {val(row, '—Ç–∏–ø')}\n"
        f"üì¶ –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: {val(row, '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ')}\n"
        f"üî¢ –ö–æ–¥: {val(row, '–∫–æ–¥')}\n"
        f"üî¢ –ü–∞—Ä—Ç –ù–æ–º–µ—Ä: {val(row, '–ø–∞—Ä—Ç –Ω–æ–º–µ—Ä')}\n"
        f"‚öôÔ∏è OEM –ü–∞—Ä—Ç –ù–æ–º–µ—Ä: {val(row, 'oem –ø–∞—Ä—Ç –Ω–æ–º–µ—Ä')}\n"
        f"üì¶ –ö–æ–ª-–≤–æ: {val(row, '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ')}\n"
        f"üí∞ –¶–µ–Ω–∞: {val(row, '—Ü–µ–Ω–∞')} {val(row, '–≤–∞–ª—é—Ç–∞')}\n"
        f"üè≠ –ò–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å: {val(row, '–∏–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å')}\n"
        f"‚öôÔ∏è OEM: {val(row, 'oem')}"
    )

def normalize(text: str) -> str:
    return re.sub(r"[^\w\s]", " ", (text or "")).lower().strip()

def squash(text: str) -> str:
    return re.sub(r"[\W_]+", "", (text or "").lower(), flags=re.UNICODE)

# ========================= GOOGLE SHEETS =========================

def _get_gs_client():
    if not CREDS_JSON.strip():
        raise RuntimeError("GOOGLE_APPLICATION_CREDENTIALS_JSON is empty or not set.")
    creds_info = json.loads(CREDS_JSON)
    creds = Credentials.from_service_account_info(creds_info, scopes=SCOPES)
    return gspread.authorize(creds)

def _open_data_worksheet(client):
    sh = client.open_by_url(SPREADSHEET_URL)
    if SHEET_NAME:
        try:
            return sh.worksheet(SHEET_NAME)
        except gspread.WorksheetNotFound:
            pass
    return sh.sheet1

def load_data_blocking() -> List[dict]:
    client = _get_gs_client()
    ws = _open_data_worksheet(client)
    return ws.get_all_records()

def _truthy(x) -> bool:
    s = str(x).strip().lower()
    return s in {"1","true","yes","y","–¥–∞","–∏—Å—Ç–∏–Ω–∞","ok","–æ–∫","allowed","—Ä–∞–∑—Ä–µ—à–µ–Ω","—Ä–∞–∑—Ä–µ—à–µ–Ω–æ"} or (s.isdigit() and int(s) > 0)

def _to_int_or_none(x):
    try:
        if x is None or (isinstance(x, float) and pd.isna(x)):
            return None
        s = str(x).strip()
        if not s:
            return None
        m = re.search(r"-?\d+", s)
        return int(m.group(0)) if m else None
    except Exception:
        return None

def load_users_from_sheet():
    client = _get_gs_client()
    sh = client.open_by_url(SPREADSHEET_URL)
    try:
        ws = sh.worksheet("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏")
    except gspread.WorksheetNotFound:
        try:
            ws = sh.worksheet("Users")
        except gspread.WorksheetNotFound:
            return set(), set(), set()

    headers_raw = ws.row_values(1) or []
    if not headers_raw:
        return set(), set(), set()

    norm_headers: List[str] = []
    seen: Set[str] = set()
    for i, h in enumerate(headers_raw, start=1):
        name = (h or "").strip() or f"col_{i}"
        lname = re.sub(r"\s+", " ", name.lower()).strip()
        base = lname
        k = 1
        while lname in seen:
            k += 1
            lname = f"{base}_{k}"
        seen.add(lname)
        norm_headers.append(lname)

    try:
        rows = ws.get_all_records(expected_headers=norm_headers)
    except Exception:
        values = ws.get_all_values()
        data_rows = values[1:] if len(values) > 1 else []
        rows = []
        for r in data_rows:
            padded = (r + [""] * (len(norm_headers) - len(r)))[:len(norm_headers)]
            rows.append({norm_headers[i]: padded[i] for i in range(len(norm_headers))})

    if not rows:
        return set(), set(), set()

    allowed, admins, blocked = set(), set(), set()
    for row in rows:
        r = {str(k).strip().lower(): v for k, v in row.items()}

        uid = (
            _to_int_or_none(r.get("user_id"))
            or _to_int_or_none(r.get("userid"))
            or _to_int_or_none(r.get("id"))
            or _to_int_or_none(r.get("uid"))
            or _to_int_or_none(r.get("—Ç–µ–ª–µ–≥—Ä–∞–º id"))
            or _to_int_or_none(r.get("–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"))
            or _to_int_or_none(r.get("user"))
        )
        if not uid:
            continue

        role = str(r.get("role") or r.get("—Ä–æ–ª—å") or "").strip().lower()
        is_admin = role in {"admin","–∞–¥–º–∏–Ω","administrator","–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä"} or _truthy(r.get("admin"))
        is_blocked = _truthy(r.get("blocked") or r.get("ban") or r.get("–∑–∞–ø—Ä–µ—Ç"))
        is_allowed = _truthy(r.get("allowed") or r.get("–¥–æ—Å—Ç—É–ø") or (not role or role == "user"))

        if is_blocked:
            blocked.add(uid)
        if is_admin:
            admins.add(uid)
            is_allowed = True
        if is_allowed and not is_blocked:
            allowed.add(uid)

    return allowed, admins, blocked

def save_issue_to_sheet_blocking(user, part: Dict[str, Any], quantity, comment: str):
    client = _get_gs_client()
    sh = client.open_by_url(SPREADSHEET_URL)
    try:
        ws = sh.worksheet("–ò—Å—Ç–æ—Ä–∏—è")
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title="–ò—Å—Ç–æ—Ä–∏—è", rows=1000, cols=12)
        ws.append_row(["–î–∞—Ç–∞", "ID", "–ò–º—è", "–¢–∏–ø", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ö–æ–¥", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–ö–æ–º–µ–Ω—Ç–∞—Ä–∏–π"])

    headers_raw = ws.row_values(1)
    headers = [h.strip() for h in headers_raw]
    norm = [h.lower() for h in headers]

    full_name = f"{(user.first_name or '').strip()} {(user.last_name or '').strip()}".strip()
    display_name = full_name or (f"@{user.username}" if getattr(user, 'username', None) else str(user.id))
    ts = now_local_str()

    values_by_key = {
        "–¥–∞—Ç–∞": ts, "timestamp": ts,
        "id": user.id, "user_id": user.id,
        "–∏–º—è": display_name, "name": display_name,
        "—Ç–∏–ø": str(part.get("—Ç–∏–ø", "")), "type": str(part.get("—Ç–∏–ø", "")),
        "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ": str(part.get("–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "")), "name_item": str(part.get("–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "")),
        "–∫–æ–¥": str(part.get("–∫–æ–¥", "")), "code": str(part.get("–∫–æ–¥", "")),
        "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ": str(quantity), "qty": str(quantity),
        "–∫–æ–º–µ–Ω—Ç–∞—Ä–∏–π": comment or "", "–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": comment or "", "comment": comment or "",
    }

    # –ü–æ–¥–≥–æ–Ω—è–µ–º –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ª–∏—Å—Ç–∞
    row = [values_by_key.get(hn, "") for hn in norm]
    ws.append_row(row, value_input_option="USER_ENTERED")

# ========================= –ò–ù–î–ï–ö–°–ê–¶–ò–Ø / –ü–û–ò–°–ö =========================

def build_search_index(df: DataFrame) -> Dict[str, Set[int]]:
    """
    –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º –∏–∑ SEARCH_COLUMNS.
    –¢–æ–∫–µ–Ω—ã ‚Äî \w+, –≤—Å—ë –≤ lower().
    """
    index: DefaultDict[str, Set[int]] = defaultdict(set)
    for col in SEARCH_COLUMNS:
        if col not in df.columns:
            continue
        # Series.items() –¥–ª—è pandas 2.x
        for idx, val in df[col].astype(str).str.lower().items():
            for t in re.findall(r"\w+", val):
                if t:
                    index[t].add(idx)
    return dict(index)

def _relevance_score(row: dict, tokens: List[str], q_squash: str) -> int:
    score = 0
    for f in SEARCH_COLUMNS:
        valx = str(row.get(f, "")).lower()
        if not valx:
            continue
        words = set(re.findall(r"\w+", valx))
        tok_hit = sum(1 for t in tokens if t in words)
        sub_hit = sum(1 for t in tokens if t and t in valx)
        sq = re.sub(r"[\W_]+", "", valx)
        squash_hit = 1 if q_squash and q_squash in sq else 0
        weight = 2 if f in ("–∫–æ–¥", "oem", "–ø–∞—Ä—Ç –Ω–æ–º–µ—Ä", "oem –ø–∞—Ä—Ç –Ω–æ–º–µ—Ä") else 1
        score += weight * (2 * tok_hit + sub_hit) + 3 * squash_hit * weight
    return score

def match_row_by_index(tokens: List[str]) -> Set[int]:
    if not _search_index:
        return set()
    result = None
    for t in tokens:
        indices = _search_index.get(t, set())
        if result is None:
            result = indices.copy()
        else:
            result &= indices
        if not result:
            break
    return result or set()

# ========================= –ö–ê–†–¢–ò–ù–ö–ò / –ò–ù–î–ï–ö–° –ò–ú–Å–ù –§–ê–ô–õ–û–í =========================

def _filename_from_url(u: str) -> str:
    from urllib.parse import urlparse, parse_qs, unquote
    u = (u or "").strip()
    if not u:
        return ""
    p = urlparse(u)
    name = unquote(p.path.rsplit("/", 1)[-1] or "")
    if not name or "." not in name:
        qnames = []
        for v in parse_qs(p.query).values():
            qnames.extend(v)
        candidates = qnames + [p.fragment]
        for cand in candidates:
            if isinstance(cand, str):
                cand = unquote(cand)
                cand_name = cand.rsplit("/", 1)[-1]
                if "." in cand_name:
                    name = cand_name
                    break
    return name

def _tokens_from_filename(u: str) -> List[str]:
    name = _filename_from_url(u)
    if not name:
        return []
    base = name.rsplit(".", 1)[0]
    fused = re.sub(r"[\W_]+", "", base.lower(), flags=re.UNICODE)
    parts = re.split(r"[\W_]+", base.lower())
    parts = [p for p in parts if p]
    seen, out = set(), []
    for t in [fused] + parts:
        if t and t not in seen:
            seen.add(t); out.append(t)
    return out

def build_image_index(df: DataFrame) -> Dict[str, str]:
    if "image" not in df.columns:
        return {}
    index: Dict[str, str] = {}
    for _, row in df.iterrows():
        url = str(row.get("image", "")).strip()
        if not url:
            continue
        tokens = _tokens_from_filename(url)
        for t in tokens:
            index.setdefault(t, url)

        # —É—Å–∏–ª–∏–º –ø–æ –∫–æ–¥–∞–º, –µ—Å–ª–∏ –∫–æ–¥ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        for col in ("–∫–æ–¥", "oem", "–ø–∞—Ä—Ç –Ω–æ–º–µ—Ä", "oem –ø–∞—Ä—Ç –Ω–æ–º–µ—Ä"):
            code_val = str(row.get(col, "")).strip().lower()
            if code_val and tokens:
                fused = tokens[0]
                raw = code_val
                sq = re.sub(r"[\W_]+", "", code_val)
                if raw and raw in fused:
                    index.setdefault(raw, url)
                if sq and sq in fused:
                    index.setdefault(sq, url)
    return index

async def find_image_by_code_async(code: str) -> str:
    if not code or not _image_index:
        return ""
    raw = (code or "").strip().lower()
    sq = re.sub(r"[\W_]+", "", raw)
    # –ø—Ä—è–º–æ–π
    hit = _image_index.get(raw) or _image_index.get(sq)
    if hit:
        return hit
    # –ø–æ–¥—Å—Ç—Ä–æ–∫–∏
    for k, url in _image_index.items():
        if (sq and sq in k) or (raw and raw in k):
            return url
    # –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
    return ""

# ---------- –ó–ê–ì–†–£–ó–ö–ê / –ö–ï–®–ò ----------

def initial_load():
    global df, _last_load_ts, _search_index, _image_index
    data = load_data_blocking()
    new_df = DataFrame(data)
    new_df.columns = new_df.columns.str.strip().str.lower()

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    for col in ("–∫–æ–¥", "oem", "–ø–∞—Ä—Ç –Ω–æ–º–µ—Ä", "oem –ø–∞—Ä—Ç –Ω–æ–º–µ—Ä"):
        if col in new_df.columns:
            new_df[col] = new_df[col].astype(str).str.strip().str.lower()
    if "image" in new_df.columns:
        new_df["image"] = new_df["image"].astype(str).str.strip()

    df = new_df
    _search_index = build_search_index(df)
    _image_index = build_image_index(df)
    _last_load_ts = time.time()

    allowed, admins, blocked = load_users_from_sheet()
    global SHEET_ALLOWED, SHEET_ADMINS, SHEET_BLOCKED, _last_users_ts
    SHEET_ALLOWED, SHEET_ADMINS, SHEET_BLOCKED = allowed, admins, blocked
    _last_users_ts = time.time()

async def ensure_fresh_data_async(force: bool = False):
    global df, _last_load_ts, _search_index, _image_index
    if not force and df is not None and (time.time() - _last_load_ts <= DATA_TTL):
        return
    data = await asyncio.to_thread(load_data_blocking)
    new_df = DataFrame(data)
    new_df.columns = new_df.columns.str.strip().str.lower()
    for col in ("–∫–æ–¥", "oem", "–ø–∞—Ä—Ç –Ω–æ–º–µ—Ä", "oem –ø–∞—Ä—Ç –Ω–æ–º–µ—Ä"):
        if col in new_df.columns:
            new_df[col] = new_df[col].astype(str).str.strip().str.lower()
    if "image" in new_df.columns:
        new_df["image"] = new_df["image"].astype(str).str.strip()

    df = new_df
    _search_index = build_search_index(df)
    _image_index = build_image_index(df)
    _last_load_ts = time.time()

def ensure_fresh_data(force: bool = False):
    # –ü–ª–∞–Ω–æ–≤–æ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ
    asyncio.create_task(ensure_fresh_data_async(force=force))

async def ensure_users_async(force: bool = False):
    global SHEET_ALLOWED, SHEET_ADMINS, SHEET_BLOCKED, _last_users_ts
    if not force and (time.time() - _last_users_ts <= USERS_TTL):
        return
    allowed, admins, blocked = await asyncio.to_thread(load_users_from_sheet)
    SHEET_ALLOWED, SHEET_ADMINS, SHEET_BLOCKED = allowed, admins, blocked
    _last_users_ts = time.time()

def ensure_users(force: bool = False):
    asyncio.create_task(ensure_users_async(force=force))

# ---------- –î–û–°–¢–£–ü–´ ----------

def is_admin(uid: int) -> bool:
    ensure_users()
    return uid in SHEET_ADMINS

def is_allowed(uid: int) -> bool:
    ensure_users()
    if uid in SHEET_BLOCKED:
        return False
    if SHEET_ALLOWED:
        # –í–ê–ñ–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∞–¥–º–∏–Ω–æ–≤ (–±–µ–∑ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–æ–π '–ú')
        return (uid in SHEET_ALLOWED) or (uid in SHEET_ADMINS)
    return True

def get_admin_ids() -> Set[int]:
    return set(SHEET_ADMINS)

# ---------- –ê–î–ê–ü–¢–ï–†–´ –î–õ–Ø –•–ï–ù–î–õ–ï–†–û–í ----------

def get_df() -> Optional[DataFrame]:
    return df

def get_image_index_copy() -> Dict[str, str]:
    return dict(_image_index or {})

